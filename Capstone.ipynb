{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM DataScience Professional Certificate\n",
    "## Applied DataScience Capstone - The Battle of Neighborhoods\n",
    "_By Kevin Gilson._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "### 1a. Business problem\n",
    "\n",
    "Young entrepreneurs are always in demand of good advices, and always looking towards the keys of success.\n",
    "DataScience can help them analyzing the market, and get information such as:\n",
    "* Which places of a city are the most prolific?\n",
    "* Which types of business are present in which areas?\n",
    "* Which types of business are lacking in which areas?\n",
    "* ...\n",
    "\n",
    "This kind of information are particularly relevant for people looking to open food related businesses.\n",
    "\n",
    "With almost 9 millions people in 2020, London is a big city. Not only is it the capital of the United Kingdom, it is also one of the top financial places in Europe, and a hugely touristic city.\n",
    "With that in mind, what could possibly leverage a young entrepreneur looking to start his Food-Truck in London, if he wanted to be successful? What is the most prevalent types of shops? Where are located the _hot_ zone of the city? Which place would be best to maximize his profit?\n",
    "\n",
    "Thanks to Data Science, we have a way to analyze raw data and come up with suggestions to help this young man, grow as a successful entrepreneur.\n",
    "And who knows, theses information might as well help him make it big in 10 years.\n",
    "\n",
    "### 1b. Data\n",
    "\n",
    "London is split into Borough, holding various Neighborhoods.\n",
    "\n",
    "In order to leverage further geographical data, we will first scrape Wikipedia to get the complete list of each Borough and Neighborhoods.\n",
    "Then, we will use Python libraries to link each Neighborhoods to its relative geographical coordinates.\n",
    "After that, we will leverage the Foursquare location data to retrieve their attributes, cluster zones, and most importantly come up with suggestions on the best places to install a food truck.\n",
    "\n",
    "Our primary data, scraped from Wikipedia, adopt the form of:\n",
    "\n",
    "|Location|London Borough|Post Town|Postcode District|Dial code|OS Grid Ref|\n",
    "|--------|--------------|---------|-----------------|---------|-----------|\n",
    "|Abbey Wood|Bexley, Greenwich [7]|LONDON|SE2|020|TQ465785|\n",
    "|Acton|Ealing, Hammersmith and Fulham[8]|LONDON|W3, W4|020|TQ205805|\n",
    "|Addington|Croydon[8]|CROYDON|CR0|020|TQ375645|\n",
    "|Addiscombe|Croydon[8]|CROYDON|CR0|020|TQ345665|\n",
    "|Albany Park|Bexley|BEXLEY, SIDCUP|DA5, DA14|020|TQ478728|\n",
    "\n",
    "As we can see, the data will need to be cleansed, but it is also important to note that OS Grid References can quite easily be converted into coordinates.\n",
    "\n",
    "### 1c. Preliminary steps\n",
    "\n",
    "Before starting our analysis, let's first import the libaries we will need along our computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression\n",
    "import re\n",
    "\n",
    "# Handle data in a vectorized way\n",
    "import numpy as np\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# JSON files\n",
    "import json\n",
    "\n",
    "# Handle GET / POST requests\n",
    "import requests\n",
    "\n",
    "# Convert an address into coordinates\n",
    "!pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Coordinates\n",
    "!pip install geocoder\n",
    "import geocoder # Geographical library\n",
    "\n",
    "# OS Grid References converter\n",
    "!pip install OSGridConverter\n",
    "from OSGridConverter import grid2latlong\n",
    "\n",
    "# Web scraping\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup # web scraping library\n",
    "\n",
    "# Parser\n",
    "!pip install lxml\n",
    "import lxml # parser library\n",
    "\n",
    "# URL opening\n",
    "import urllib.request as req # URL opening library\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Map rendering\n",
    "!pip install folium==0.5.0\n",
    "import folium\n",
    "\n",
    "# Python ENV file\n",
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Password input\n",
    "import getpass\n",
    "\n",
    "# Importation confirmation\n",
    "print('Libraries installed and imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Retrieve the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Scrape the WikiPedia page\n",
    "\n",
    "As the first step, we will need to scrape the WikiPedia page in order to retrieve its table, and therefore datas about the London Districts and Areas.\n",
    "In order to do so, we will:\n",
    "1. Scrape the page using BeautifulSoup;\n",
    "2. Convert the OS Grid References found to coordinates (latitude, longitude) using the OSGRridConverter library; missing OS Grid References will results in NaN values for their coordinates;\n",
    "3. Check the shape of the recovered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting dataframe has a shape of: (533, 8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>London Borough</th>\n",
       "      <th>Post Town</th>\n",
       "      <th>Post District</th>\n",
       "      <th>Dial Code</th>\n",
       "      <th>OS Grid Ref</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbey Wood</td>\n",
       "      <td>Bexley,  Greenwich [7]</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SE2</td>\n",
       "      <td>020</td>\n",
       "      <td>TQ465785</td>\n",
       "      <td>51.4865</td>\n",
       "      <td>0.109318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acton</td>\n",
       "      <td>Ealing, Hammersmith and Fulham[8]</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>W3, W4</td>\n",
       "      <td>020</td>\n",
       "      <td>TQ205805</td>\n",
       "      <td>51.5106</td>\n",
       "      <td>-0.264585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addington</td>\n",
       "      <td>Croydon[8]</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>CR0</td>\n",
       "      <td>020</td>\n",
       "      <td>TQ375645</td>\n",
       "      <td>51.3629</td>\n",
       "      <td>-0.0257799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addiscombe</td>\n",
       "      <td>Croydon[8]</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>CR0</td>\n",
       "      <td>020</td>\n",
       "      <td>TQ345665</td>\n",
       "      <td>51.3816</td>\n",
       "      <td>-0.0681255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany Park</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>BEXLEY, SIDCUP</td>\n",
       "      <td>DA5, DA14</td>\n",
       "      <td>020</td>\n",
       "      <td>TQ478728</td>\n",
       "      <td>51.4349</td>\n",
       "      <td>0.125663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location                     London Borough       Post Town  \\\n",
       "0   Abbey Wood             Bexley,  Greenwich [7]          LONDON   \n",
       "1        Acton  Ealing, Hammersmith and Fulham[8]          LONDON   \n",
       "2    Addington                         Croydon[8]         CROYDON   \n",
       "3   Addiscombe                         Croydon[8]         CROYDON   \n",
       "4  Albany Park                             Bexley  BEXLEY, SIDCUP   \n",
       "\n",
       "  Post District Dial Code OS Grid Ref Latitude  Longitude  \n",
       "0           SE2       020    TQ465785  51.4865   0.109318  \n",
       "1        W3, W4       020    TQ205805  51.5106  -0.264585  \n",
       "2           CR0       020    TQ375645  51.3629 -0.0257799  \n",
       "3           CR0       020    TQ345665  51.3816 -0.0681255  \n",
       "4     DA5, DA14       020    TQ478728  51.4349   0.125663  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_wiki = \"https://en.wikipedia.org/wiki/List_of_areas_of_London\"\n",
    "\n",
    "# Scrape the page with BeautifulSoup\n",
    "page = req.urlopen(url_wiki)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "all_tables = soup.find_all(\"table\")\n",
    "\n",
    "# Initiate the dataframe\n",
    "column_names = ['Location', 'London Borough', 'Post Town',\n",
    "                'Post District', 'Dial Code', 'OS Grid Ref',\n",
    "                'Latitude', 'Longitude']\n",
    "wiki_data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Loop through the scraping and extract the second table (first one is the Contents)\n",
    "for row in all_tables[1].find_all('tr'):\n",
    "    cells = row.findAll('td')\n",
    "    if len(cells)==6:\n",
    "        #print(cells)\n",
    "        wiki_location = cells[0].text.strip()\n",
    "        wiki_borough = cells[1].text.strip()\n",
    "        wiki_town = cells[2].text.strip()\n",
    "        wiki_district = cells[3].text.strip()\n",
    "        wiki_dial = cells[4].text.strip()\n",
    "        \n",
    "        wiki_gridref = cells[5].text.strip()\n",
    "        try:\n",
    "            wiki_latlong = grid2latlong(wiki_gridref)\n",
    "        except:\n",
    "            wiki_latlong.latitude = 'NaN'\n",
    "            wiki_latlong.longitude = 'NaN'\n",
    "        \n",
    "        wiki_data = wiki_data.append({'Location': wiki_location,\n",
    "                                     'London Borough': wiki_borough,\n",
    "                                     'Post Town': wiki_town,\n",
    "                                     'Post District': wiki_district,\n",
    "                                     'Dial Code': wiki_dial,\n",
    "                                     'OS Grid Ref': wiki_gridref,\n",
    "                                     'Latitude': wiki_latlong.latitude,\n",
    "                                     'Longitude': wiki_latlong.longitude}\n",
    "                                    , ignore_index=True)\n",
    "\n",
    "# Check the results\n",
    "print(\"The resulting dataframe has a shape of: {}\\n\".format(wiki_data.shape))\n",
    "wiki_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Upgrade the data\n",
    "\n",
    "We can see that the resulting dataframe isn't looking its best; let's upgrade it a bit:\n",
    "1. First we will drop columns that won't be used later;\n",
    "2. Then we will rename a few of the remaining ones into clearer names;\n",
    "3. Finally we will reorder the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Town</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bexley,  Greenwich [7]</td>\n",
       "      <td>Abbey Wood</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>51.4865</td>\n",
       "      <td>0.109318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ealing, Hammersmith and Fulham[8]</td>\n",
       "      <td>Acton</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>51.5106</td>\n",
       "      <td>-0.264585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Croydon[8]</td>\n",
       "      <td>Addington</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>51.3629</td>\n",
       "      <td>-0.0257799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croydon[8]</td>\n",
       "      <td>Addiscombe</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>51.3816</td>\n",
       "      <td>-0.0681255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>Albany Park</td>\n",
       "      <td>BEXLEY, SIDCUP</td>\n",
       "      <td>51.4349</td>\n",
       "      <td>0.125663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Borough Neighborhood            Town Latitude  \\\n",
       "0             Bexley,  Greenwich [7]   Abbey Wood          LONDON  51.4865   \n",
       "1  Ealing, Hammersmith and Fulham[8]        Acton          LONDON  51.5106   \n",
       "2                         Croydon[8]    Addington         CROYDON  51.3629   \n",
       "3                         Croydon[8]   Addiscombe         CROYDON  51.3816   \n",
       "4                             Bexley  Albany Park  BEXLEY, SIDCUP  51.4349   \n",
       "\n",
       "   Longitude  \n",
       "0   0.109318  \n",
       "1  -0.264585  \n",
       "2 -0.0257799  \n",
       "3 -0.0681255  \n",
       "4   0.125663  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop useless columns\n",
    "wiki_data.drop(columns=['Post District'\n",
    "                        ,'Dial Code'\n",
    "                        ,'OS Grid Ref'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "wiki_data.rename(columns={'Location':'Neighborhood'\n",
    "                          ,'London Borough':'Borough'\n",
    "                          ,'Post Town':'Town'}, inplace=True)\n",
    "\n",
    "# Reorder\n",
    "wiki_data = wiki_data[['Borough'\n",
    "                       ,'Neighborhood'\n",
    "                       ,'Town'\n",
    "                       ,'Latitude'\n",
    "                       ,'Longitude']]\n",
    "#\n",
    "wiki_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Clean the data\n",
    "\n",
    "We can see a few problems with our data, such as:\n",
    "* Some values contains WikiPedia links references (i.e. \"[1]\");\n",
    "* Some Neighborhoods are affected to two or more Towns;\n",
    "* Some values are followed by explainations in between paratheses;\n",
    "* The case of the data are not normalized, mixing upper and lower cases.\n",
    "\n",
    "Let's define a function that will use regular expression to clean the data of brackets, parentheses, and others.\n",
    "And then, let's capitalize each value (i.e. \"VALUES\" and \"values\" will become \"Values\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Town</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>Abbey Wood</td>\n",
       "      <td>London</td>\n",
       "      <td>51.4865</td>\n",
       "      <td>0.109318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>Acton</td>\n",
       "      <td>London</td>\n",
       "      <td>51.5106</td>\n",
       "      <td>-0.264585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>Addington</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>51.3629</td>\n",
       "      <td>-0.0257799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>Addiscombe</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>51.3816</td>\n",
       "      <td>-0.0681255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>Albany Park</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>51.4349</td>\n",
       "      <td>0.125663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Borough Neighborhood     Town Latitude  Longitude\n",
       "0   Bexley   Abbey Wood   London  51.4865   0.109318\n",
       "1   Ealing        Acton   London  51.5106  -0.264585\n",
       "2  Croydon    Addington  Croydon  51.3629 -0.0257799\n",
       "3  Croydon   Addiscombe  Croydon  51.3816 -0.0681255\n",
       "4   Bexley  Albany Park   Bexley  51.4349   0.125663"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning function, based on RegEx patterns\n",
    "def Clean_DataEnd(raw_data, pattern):\n",
    "    if re.search(pattern, str(raw_data)):\n",
    "        pos = re.search(pattern, str(raw_data)).start()\n",
    "        return raw_data[:pos]\n",
    "    else:\n",
    "        return raw_data\n",
    "\n",
    "# Fix wikipedia references, double values, and annotations\n",
    "for col in wiki_data.select_dtypes(include='object').columns:\n",
    "    wiki_data[col] = wiki_data[col].apply(Clean_DataEnd, pattern=' \\[.*')\n",
    "    wiki_data[col] = wiki_data[col].apply(Clean_DataEnd, pattern='\\[.*')\n",
    "    wiki_data[col] = wiki_data[col].apply(Clean_DataEnd, pattern=' \\(.*')\n",
    "    wiki_data[col] = wiki_data[col].apply(Clean_DataEnd, pattern=', .*')\n",
    "    wiki_data[col] = wiki_data[col].apply(Clean_DataEnd, pattern=' and .*')\n",
    "                       \n",
    "# Capitalize data - Use title to capitalize each words\n",
    "for col in ['Borough','Neighborhood','Town']:\n",
    "    wiki_data[col] = wiki_data[col].str.title()\n",
    "\n",
    "# Check\n",
    "wiki_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Handle missing values\n",
    "\n",
    "Before going further, we want to make sure that we have the coordinates of each neighborhoods.\n",
    "Let's check the Latitudes and Longitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Borough Neighborhood       Town Latitude Longitude\n",
      "53    Bexley      Blendon     Bexley      NaN       NaN\n",
      "233  Bromley    Hazelwood  Orpington      NaN       NaN\n",
      "     Borough Neighborhood       Town Latitude Longitude\n",
      "53    Bexley      Blendon     Bexley      NaN       NaN\n",
      "233  Bromley    Hazelwood  Orpington      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "print(wiki_data[wiki_data['Latitude'] == 'NaN'])\n",
    "print(wiki_data[wiki_data['Longitude'] == 'NaN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two Neighborhoods are missing their coordinates.\n",
    "\n",
    "Using the GeoCoder library, let's retrieve their latitudes and longitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Borough, Neighborhood, Town, Latitude, Longitude]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Borough, Neighborhood, Town, Latitude, Longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve the coordinates, using ArcGis instead of Google for better performances\n",
    "def GetCoordinates(df):\n",
    "    bor = df['Borough']\n",
    "    neigh = df['Neighborhood']\n",
    "    town = df['Town']\n",
    "    \n",
    "    lat_lng_coords = None\n",
    "    while(lat_lng_coords is None):\n",
    "        g = geocoder.arcgis('{}, London'.format(neigh))\n",
    "        lat_lng_coords = g.latlng\n",
    "    lat = lat_lng_coords[0]\n",
    "    long = lat_lng_coords[1]\n",
    "    lst = {'Borough': bor,\n",
    "           'Neighborhood': neigh,\n",
    "           'Town': town,\n",
    "           'Latitude': lat,\n",
    "           'Longitude': long}\n",
    "    return pd.Series(lst)\n",
    "\n",
    "# Apply the function to missing coordinates\n",
    "wiki_data[wiki_data['Latitude'] == 'NaN'] = wiki_data[wiki_data['Latitude'] == 'NaN'].apply(GetCoordinates, axis=1)\n",
    "\n",
    "# Check if there is any remaining NaN values\n",
    "print(wiki_data[wiki_data['Latitude'] == 'NaN'])\n",
    "print(wiki_data[wiki_data['Longitude'] == 'NaN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
